# -*- coding: utf-8 -*-
"""CV_Lab1_part1and2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DGQBvPPYYhvT-bm10vHKcXe0L8OpQ-_x

Ξεκινάμε κάνοντας όλα τα απαραίτητα import
"""

import cv2

import matplotlib.pyplot as plt

import numpy as np

import math

import sys

from matplotlib.patches import Circle

from scipy import ndimage

from sklearn.preprocessing import MinMaxScaler

"""Eπίσης κάνουμε mount το drive για να υπάρχει όλο το material στη διάθεσή μας."""

# Commented out IPython magic to ensure Python compatibility.
# mount drive
from google.colab import drive
drive.mount('/content/drive')

# change to lab1 directory
# %cd /content/drive/MyDrive/CV_Labs/Lab1

"""# **Μέρος 1: Ανίχνευση Ακμών σε Γκρίζες Εικόνες**

##1.1. Δημιουργία Εικόνων Εισόδου

###1.1.1

Αρχικά διαβάζουμε την εικόνα “edgetest 23.png”.
"""

# Read grayscale image
img = cv2.imread('edgetest_23.png', cv2.IMREAD_GRAYSCALE)

print("Resolution: ", img.shape)
print("Range: %d - %d " % (img.min(), img.max()))

# Normalize to [0,1]
#img = img.astype(np.float32)/img.max()

# Show image
plt.imshow(img, cmap='gray')

"""###1.1.2

**i**. 
H μέγιστη τιμή pixel είναι το άσπρο(255) και η ελάχιστη είναι το μαύρο(0).

Αρχικά βρίσκουμε τη τιμή της τυπικής απόκλισης για PSNR=20 dB, η οποία είναι σ = 25.5. Χρησιμοποιούμε τώρα αυτή τη τιμή για τη παραμετροποίηση του λευκού θορύβου.

Για να προσθέσουμε Gaussian θόρυβο πρέπει πρώτα να δημιουργήσουμε μια μηδενική εικόνα με ίδιες διαστάσεις με την αρχική. Έπειτα χρησιμοποιούμε μια random distribution για να υπολογίσουμε τις τιμές των pixel του θορύβου n(x,y) [με μέση τιμή μ=0 και τυπική απόκλιση σ=25.5]
"""

#Creating gaussian noise
mean = 0
sigma = 25.5

Imax = img.max()
Imin = img.min()

gauss_noise=np.zeros((512,512),dtype=np.uint8)
gaussian = np.random.normal(mean, sigma, (512, 512)).astype(np.float32)
gauss_noise=(gaussian*0.5).astype(np.uint8)

#adding noise
noise_img = img + gaussian

#Displaying the image with noise PSNR = 20dB
fig=plt.figure(dpi=250)

fig.add_subplot(1,3,1)
plt.imshow(img,cmap='gray')
plt.axis("off")
plt.title("Original")

fig.add_subplot(1,3,2)
plt.imshow(gauss_noise,cmap='gray')
plt.axis("off")
plt.title("Gaussian Noise")

fig.add_subplot(1,3,3)
plt.imshow(noise_img,cmap='gray')
plt.axis("off")
plt.title("Combined")

#plt.savefig('PSNR20.jpg',format='png', bbox_inches='tight')

"""**ii**. PSNR = 10 dB , η τυπική απόκλιση τώρα είναι σ2 = 80.64"""

#Creating noise 
mean = 0
sigma = 80.64

gauss_noise2=np.zeros((512,512),dtype=np.uint8)
gaussian2 = np.random.normal(mean, sigma, (512, 512)).astype(np.float32)
gauss_noise2=(gaussian2*0.5).astype(np.uint8)

#adding noise
noise_img2 = img + gaussian2

#Displaying image with noise PSNR = 10dB
fig=plt.figure(dpi=250)

fig.add_subplot(1,3,1)
plt.imshow(img,cmap='gray')
plt.axis("off")
plt.title("Original")

fig.add_subplot(1,3,2)
plt.imshow(gauss_noise2,cmap='gray')
plt.axis("off")
plt.title("Gaussian Noise")

fig.add_subplot(1,3,3)
plt.imshow(noise_img2,cmap='gray')
plt.axis("off")
plt.title("Combined")

#plt.savefig('PSNR10.jpg',format='png', bbox_inches='tight')

"""Όπως βλέπουμε ο θόρυβος με μικρή τιμή PSNR οδηγεί σε εικόνα με χαμηλότερα επίπεδα θορύβου στην εικόνα ( signal to noise ratio ).

##1.2 Υλοποίηση Αλγορίθμων Ανίχνευσης Ακμών

###1.2.1

Ξεκινάμε υλοποιώντας τα φίλτρα gaussian και laplacian of gaussian
"""

#Functions for creating LoG kernel
def LoG(sigma):
  
  n = int(2*np.ceil(3*sigma)+1)
  ax = np.linspace(-n/2, n/2, n)
    
  xx, yy = np.meshgrid(ax, ax)
    
  kernel = ((-1)/(np.pi*sigma**4))*((1-(xx**2+yy**2)/(2*sigma**2)))* np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma))
  return kernel


def kernels(sigma):
  """This function takes as input the variance value and returns
  a gaussian kernel and a LoG kernel created with this sigma value
  """

  #Dimensions of the kernel should be odd number 
  ksize = int(2*np.ceil(3*sigma)+1) 

  # Creates a 2-D Gaussian kernel
  gauss_kernel = cv2.getGaussianKernel(ksize, sigma)
  gauss_2d = gauss_kernel @ gauss_kernel.T

  log_kernel = LoG(sigma)
  
  return gauss_2d, log_kernel

#Example for sigma = 1
x, y = kernels(1)

print("Gaussian coefficients are:")
print(x)
print("Laplacian of gaussian kernel is:")
print(y)

s = [0.5, 1.5, 3]
logs =[]
for i in s:
  _ , log = kernels(i)
  logs.append(log)

fig = plt.figure(dpi=200)

fig.add_subplot(1,3,1)
plt.imshow(cv2.filter2D(noise_img, -1, logs[0]), cmap='gray')
plt.axis('off')

fig.add_subplot(1,3,2)
plt.imshow(cv2.filter2D(noise_img, -1, logs[1]), cmap='gray')
plt.axis('off')

fig.add_subplot(1,3,3)
plt.imshow(cv2.filter2D(noise_img, -1, logs[2]), cmap='gray')
plt.axis('off')

"""###1.2.2

Η μη-γραμμική προσέγγιση γίνεται στην εξομαλυμένη εικόνα Iσ οπότε αρχικά περνάμε την αρχική εικόνα απο το gaussian filter για να γίνει το απαραίτητο smoothing. Παρακάτω φαίνεται η συνάρτηση που υλοποιεί τις δύο προσεγγίσεις ανάλογα με τη τιμή της παραμέτρου analysis.
"""

def laplaceImage(analysis,sigma, g_img):
  #Creating kernels based on sigma
  gaussian, log = kernels(sigma)

  """If analysis is linear the Laplacian is applied via the LoG kernel 
  with a linear approach, where if analysis is non_linear, the Laplacian is obtained using
  morphological filters"""
  
  if analysis == "linear":
    # Applying the filter2D() function
    L1 = cv2.filter2D(src=g_img, ddepth=-1, kernel=log)
    L = L1

  elif analysis == "non_linear":
    smooth_img = cv2.filter2D(g_img,-1,gaussian)
    # Create morphological kernel
    kernel = np.array([
        [0,1,0],
        [1,1,1],
        [0,1,0]
], dtype=np.uint8)

    #Functions
    img_erosion = cv2.erode(smooth_img, kernel)
    img_dilation = cv2.dilate(smooth_img, kernel)

    L2 = img_erosion + img_dilation - (smooth_img*2)
    L = L2

  return L

plt.imshow(laplaceImage('non_linear', 1.5, noise_img),cmap='gray')
plt.axis('off')

#plt.savefig('LoG_image_nonlinear.jpg', format='png', bbox_inches='tight')

"""###1.2.3"""

def findOutline(L):
  """This function returns all the possible zerocrossings of the log image taken as input"""

  # Convert to binary with thresholding
  _, outline_img = cv2.threshold(L, 0.5, 1, cv2.THRESH_BINARY)

  # Create morphological kernel
  kernel = np.array([
      [0,1,0],
      [1,1,1],
      [0,1,0]
  ], dtype=np.uint8)

  #Functions
  Y1 = cv2.erode(outline_img, kernel)
  Y2 = cv2.dilate(outline_img, kernel)

  Y = np.subtract(Y1,Y2)

  return Y

#Example showing all the possible zerocrossings("edges") using linear and non-linear approach with sigma=0.5
l_img_linear = laplaceImage('linear', 3, noise_img)
l_img_nonlinear = laplaceImage('non_linear', 3, noise_img)

outline_linear = findOutline(l_img_linear)
outline_nonlinear = findOutline(l_img_nonlinear)

fig = plt.figure(dpi=150)

fig.add_subplot(1,2,1)
plt.imshow(outline_linear,'gray')
plt.axis('off')
plt.title('linear')

fig.add_subplot(1,2,2)
plt.imshow(outline_nonlinear,'gray')
plt.axis('off')
plt.title('non-linear')

#plt.savefig('zerocrossing0_5.jpg',format='png', bbox_inches='tight')

"""Tο αποτέλεσμα που παίρνουμε είναι οι ακμές μας αλλά με λίγο "θόρυβο" εντός των σχημάτων. Στη περίπτωση αυτή ανιχνεύονται όλες οι μη απαραίτητες λεπτομέρεις που μερικές οφείλονται και στο θόρυβο της εικόνας.

###1.2.4
"""

sigma = 1.5
gaussian, log = kernels(sigma)
smooth_img = cv2.filter2D(noise_img,-1,gaussian)

def norma(arr1, arr2, i,j):
  #Computes the norma of two given arrays

  return np.sqrt(np.power(arr1[i][j],2) + np.power(arr2[i][j],2))


def max_grad(image):
  #Computes the maximum value of gradient of an image

  Ix, Iy = image.shape
  list_of_norms = []
  gradient = np.gradient(image)

  #calculating all norms of the image
  for i in range(Ix):
    for j in range(Iy):
      list_of_norms.append(norma(gradient[0], gradient[1], i, j))

  #maximum of all norms
  max_of_grad = max(list_of_norms)
  return max_of_grad, list_of_norms


def zeroCrossings(Image, Y, theta):
  #Accepts only the zerocrossings where image has large grad

  #dimensions
  Ix, Iy = Image.shape

  max_of_grad, list_of_norms = max_grad(Image)

  list_of_norms2D = np.reshape(list_of_norms, (Ix,Iy))

  condition = theta*max_of_grad

  #arr is 1 only in the points where gradient of the image has value greater of the condition
  arr = np.zeros((Ix,Iy), dtype=np.uint8)

  for x in range(Ix):
    for y in range(Iy):
      #Keep those where both conditions are fulfielled
      if list_of_norms2D[x][y] > condition: 
        arr[x][y] = 1
  
  #Keep those where both conditions are fulfielled
  Y = Y.astype(int)
  zero_crossings = Y & arr

  return zero_crossings

#Plotting zero-crossings for sigma = 1.5 and θedge = 0.2

plt.imshow(zeroCrossings(smooth_img, l_img_linear, 0.2),'gray')
plt.axis('off')

#plt.savefig('zeroCrossing.jpg',format='png', bbox_inches='tight')

"""Γενικά, όσο μικρότερο σ χρησιμοποιούμε για το LoG φίλτρο τόσο πιο πολλά zerocrossings θα ανιχνευθούν, τόσο πιο λεπτομερής θα είναι η αναζήτηση (κλίμακα). Όσο αυξάνουμε τη τυπική απόκλιση τα zerocrossings που ανιχνεύονται λιγοστεύουν και αποτελούν τις κύριες και πιο ισχυρές ακμές χωρίς θόρυβο. Επομένως η επιλογή του θedge θα γίνει αναλόγως το σ που χρησιμοποιήσαμε. Μικρό σ απαιτεί μεγάλο θ ώστε να περάσει το κατώφλι όσο περισσότερος θόρυβος γίνεται, αντίθετα για μεγάλο σ χρειαζόμαστε μικρό θ διότι τα zerocrossings που ανιχνεύσαμε είναι ήδη τα περισσότερα σωστά.

Παρακάτω, συγκεντρώνουμε όλες τις συναρτήσεις για να φτιάξουμε τη συνάρτηση EdgeDetect η οποία θα βρίσκει ακμές σε μια εικόνα σύμφωνα με τη μέθοδο της Λαπλασιανής της Γκαουσιανής και την εύρεση των zero-crossings.
"""

def EdgeDetect(I, sigma, theta, analysis):
  """Takes as input
  I: image
  sigma: variance
  theta: θedge
  analysis: linear/non_linear
  
  Detects edges of the noised image"""

  #Dimensions
  Ix, Iy = I.shape

  gaussian, laplacian = kernels(sigma)
  smooth_img = cv2.filter2D(I,-1,gaussian)

  laplacian_img = laplaceImage(analysis, sigma, I)

  zeros = findOutline(laplacian_img)

  edges = zeroCrossings(smooth_img, zeros, theta)

  return edges

#Example of edge detection for sigma = 1.5, θcorn = 0.2, and non_linear analysis
img_detect = EdgeDetect(noise_img, 1.5 , 0.2, 'linear')

plt.imshow(img_detect, cmap='gray')
plt.axis('off')

"""##1.3 Αξιολόγηση των Αποτελεσμάτων Ανίχνευσης Ακμών

###1.3.1

Βρίσκουμε τις αληθινές εικόνες με μη-γραμμικό τρόπο.
"""

# Create morphological kernel
kernel = np.array([
    [0,1,0],
    [1,1,1],
    [0,1,0]
], dtype=np.uint8)

#Functions
S1 = cv2.erode(img, kernel)
S2 = cv2.dilate(img, kernel)

M = S2-S1

# Convert to binary with thresholding
_, True_edges = cv2.threshold(M, 0.5, 1, cv2.THRESH_BINARY)

#edges with black
plt.imshow(True_edges,'gray')

#plt.savefig('True_edges.jpg',format='png', bbox_inches='tight')

"""###1.3.2"""

def Accuracy(img, sigma, theta, analysis, true_edges):


  scout_edges = EdgeDetect(img, sigma , theta, analysis)
  true_edges = true_edges

  #cardinality
  cardD = scout_edges.sum()
  cardT = true_edges.sum()
  
  S = scout_edges & true_edges
  cardS = S.sum()

  recall = cardS/cardT
  precision = cardS/cardD

  quality = (precision + recall)/2

  return recall, precision, quality

"""###1.3.3 Σχολιασμός Αποτελεσμάτων για διάφορες παραμέτρους.

Παρακάτω, εμφανίσαμε για τις διάφορες τιμές του σ και του θ, τη ποιότητα της ανίχνευσης ακμών, με γραμμικό και μη γραμμικό τρόπο και για τις δύο εικόνες με θόρυβο (PSNR=10/20). Παρουσιάζουμε στις εικόνες τα καλύτερα αποτελέσματα.
"""

sigma_compare = [0.5, 1, 1.5, 2, 2.5]
theta_compare = [0.1, 0.15, 0.18, 0.2, 0.25, 0.3]


def corner_parameter_analysis(img, sigma, theta, analysis, true_edges, PSNR):

  best_params = [0,0,0,0,0]
  best_quality = 0
  quality=[]
  all_params = []
  for s in sigma:
    for t in theta:
      a, r, q = Accuracy(img, s, t, analysis, true_edges)
      all_params.append((s, t, q))
      if best_quality < q:
        best_quality = q
        q = round(q,4)
        best_params = [s, t, analysis, PSNR, q*100]
    quality.append(best_quality)

  return best_quality, best_params, quality, all_params
      

best_quality1, best_params1, quality1, all_params1 = corner_parameter_analysis(noise_img, sigma_compare, theta_compare, 'linear', True_edges, 20)
best_quality2, best_params2, quality2, all_params2 = corner_parameter_analysis(noise_img2, sigma_compare, theta_compare, 'linear', True_edges, 10)
best_quality3, best_params3, quality3, all_params3 = corner_parameter_analysis(noise_img, sigma_compare, theta_compare, 'non_linear', True_edges, 20)
best_quality4, best_params4, quality4, all_params4 = corner_parameter_analysis(noise_img2, sigma_compare, theta_compare, 'non_linear', True_edges, 10)

best_img1 = EdgeDetect(noise_img, best_params1[0], best_params1[1], best_params1[2])
best_img2 = EdgeDetect(noise_img2, best_params2[0], best_params2[1], best_params2[2])
best_img3 = EdgeDetect(noise_img, best_params3[0], best_params3[1], best_params3[2])
best_img4 = EdgeDetect(noise_img2, best_params4[0], best_params4[1], best_params4[2])


fig = plt.figure(dpi=150)

fig.add_subplot(2,2,1)
plt.imshow(best_img1, cmap='gray')
plt.axis('off')
plt.title(best_params1)

fig.add_subplot(2,2,2)
plt.imshow(best_img2, cmap='gray')
plt.axis('off')
plt.title(best_params2)

fig.add_subplot(2,2,3)
plt.imshow(best_img3, cmap='gray')
plt.axis('off')
plt.title(best_params3)

fig.add_subplot(2,2,4)
plt.imshow(best_img4, cmap='gray')
plt.axis('off')
plt.title(best_params4)

#plt.savefig('Quality_plot.jpg',format='png', bbox_inches='tight')

'''
all_params1.sort(key = lambda x: x[2])
print(all_params1[-10:])

print(all_params3)

all_params2.sort(key = lambda x: x[2])
print(all_params2[-10:])

print(all_params4)
'''

"""##1.4  Εφαρμογή των Αλγορίθμων Ανίχνευσης Ακμών σε Πραγματικές εικόνες

###1.4.1
"""

# Read image
kyot_img = cv2.imread('kyoto_edges.jpg')

kyot_img = cv2.cvtColor(kyot_img, cv2.COLOR_BGR2RGB)


print("Resolution: ", kyot_img.shape)
print("Range: %d - %d " % (kyot_img.min(), kyot_img.max()))

plt.imshow(kyot_img)

kyot_img_gray = cv2.cvtColor(kyot_img, cv2.COLOR_RGB2GRAY)

plt.imshow(kyot_img_gray, cmap='gray')

"""###1.4.2 Σχολιασμός αποτελεσμάτων."""

edges_linear = (EdgeDetect(I = kyot_img_gray, sigma = 1 , theta= 0.18, analysis = "linear"))
edges_nonlinear = (EdgeDetect(I = kyot_img_gray, sigma = 2 , theta= 0.15, analysis = "non_linear"))

fig = plt.figure(dpi=200)
fig.subplots_adjust(wspace = 0.01)


fig.add_subplot(1,2,1)
plt.imshow(edges_linear, 'gray')
plt.axis('off')

fig.add_subplot(1,2,2)
plt.imshow(edges_nonlinear, 'gray')
plt.axis('off')

plt.savefig('quality_plot_final.png',format='png',transparent=True, bbox_inches='tight')

"""# **Μέρος 2: Ανίχνευση Σημείων Ενδιαφέροντος (Interest Point Detection)**

## 2.1. Ανίχνευση Γωνιών

### 2.1.1
"""

#Images
cells_img = cv2.imread('cells.jpg')
cells_img = cv2.cvtColor(cells_img, cv2.COLOR_BGR2RGB)
up_img = cv2.imread('up.png')
up_img = cv2.cvtColor(up_img, cv2.COLOR_BGR2RGB)
cells_img_gray = cv2.imread('cells.jpg',cv2.IMREAD_GRAYSCALE)
up_img_gray = cv2.imread('up.png',cv2.IMREAD_GRAYSCALE)

fig = plt.figure(dpi=200)

fig.add_subplot(1,4,1)
plt.imshow(cells_img)
plt.axis('off')
plt.title(cells_img.shape)


fig.add_subplot(1,4,2)
plt.imshow(up_img)
plt.axis('off')
plt.title(up_img.shape)

fig.add_subplot(1,4,3)
plt.imshow(cells_img_gray,cmap='gray')
plt.axis('off')
plt.title(cells_img_gray.shape)


fig.add_subplot(1,4,4)
plt.imshow(up_img_gray,cmap='gray')
plt.axis('off')
plt.title(up_img_gray.shape)

#Recommended vaules:
sigma = 2
r = 2.5
k = 0.1
theta_corn = 0.05
s = 1.5
N = 4

"""Βρίσκουμε τα στοιχεία J1, J2, J3 του τανυστή J"""

#Creating tensor J for an image I

def tensor_J(image, s, r):
  """This function returns elements J1,J2,J3 of tensor J of an image"""
  
  #Defining gaussian kernels
  ksize_s = int(np.ceil(3*s)*2 + 1)
  ksize_r = int(np.ceil(3*r)*2 + 1)

  g_kernel_s = cv2.getGaussianKernel(ksize_s, s)
  g_kernel_r = cv2.getGaussianKernel(ksize_r, r)

  #Smoothing images
  image_smoothed = cv2.filter2D(image, -1, g_kernel_s)

  #Calculating gradients
  gradients= np.gradient(image_smoothed)

  first_mult= np.multiply(gradients[0], gradients[0])
  second_mult= np.multiply(gradients[0],gradients[1])
  third_mult= np.multiply(gradients[1],gradients[1])
  
  J1= cv2.filter2D(first_mult, -1, g_kernel_r)
  J2= cv2.filter2D(second_mult, -1, g_kernel_r)
  J3= cv2.filter2D(third_mult, -1, g_kernel_r)

  return J1,J2,J3

J1_k,J2_k,J3_k = tensor_J(kyot_img_gray, sigma, r)
J1_c, J2_c, J3_c = tensor_J(cells_img_gray, sigma, r)
J1_u, J2_u, J3_u = tensor_J(up_img_gray, sigma, r)

fig = plt.figure(dpi=200)

fig.add_subplot(3,3,1)
plt.imshow(J1_k,cmap='gray')
plt.axis('off')
plt.title('J1 for kyot image')

fig.add_subplot(3,3,2)
plt.imshow(J2_k,cmap='gray')
plt.axis('off')
plt.title('J2 for kyot image')

fig.add_subplot(3,3,3)
plt.imshow(J3_k,cmap='gray')
plt.axis('off')
plt.title('J3 for kyot image')

fig.add_subplot(3,3,4)
plt.imshow(J1_c,cmap='gray')
plt.axis('off')
plt.title('J1 for cells image')

fig.add_subplot(3,3,5)
plt.imshow(J2_c,cmap='gray')
plt.axis('off')
plt.title('J2 for cells image')

fig.add_subplot(3,3,6)
plt.imshow(J3_c,cmap='gray')
plt.axis('off')
plt.title('J3 for cells image')

fig.add_subplot(3,3,7)
plt.imshow(J1_u,cmap='gray')
plt.axis('off')
plt.title('J1 for up image')

fig.add_subplot(3,3,8)
plt.imshow(J2_u,cmap='gray')
plt.axis('off')
plt.title('J2 for up image')

fig.add_subplot(3,3,9)
plt.imshow(J3_u,cmap='gray')
plt.axis('off')
plt.title('J3 for up image')

#plt.savefig('tensorJ.jpg',format='png', bbox_inches='tight')

"""###2.1.2

Υπολογισμός των ιδιοτιμών λ- και λ+
"""

def lamda_values(J1,J2,J3):
  #Returns the eigenvalues
  lamda_plus= 0.5*np.add(np.add(J1,J3),np.sqrt(np.add(np.power((np.subtract(J1,J3)),2),4*np.power(J2,2))))

  lamda_minus= 0.5*np.subtract(np.add(J1,J3),np.sqrt(np.add(np.power((np.subtract(J1,J3)),2),4*np.power(J2,2))))

  return lamda_plus, lamda_minus

lamda_k = ((lamda_values(J1_k, J2_k, J3_k)))

lamda_c = ((lamda_values(J1_c, J2_c, J3_c)))

lamda_u = ((lamda_values(J1_u, J2_u, J3_u)))


fig = plt.figure(dpi=200)

fig.add_subplot(3,2,1)
plt.imshow(lamda_k[0],cmap='gray')
plt.axis('off')
plt.title('lamda_plus for kyot')

fig.add_subplot(3,2,2)
plt.imshow(lamda_k[1],cmap='gray')
plt.axis('off')
plt.title('lamda_minus for kyot')

fig.add_subplot(3,2,3)
plt.imshow(lamda_c[0],cmap='gray')
plt.axis('off')
plt.title('lamda_plus for cells')

fig.add_subplot(3,2,4)
plt.imshow(lamda_c[1],cmap='gray')
plt.axis('off')
plt.title('lamda_minus for cells')

fig.add_subplot(3,2,5)
plt.imshow(lamda_u[0],cmap='gray')
plt.axis('off')
plt.title('lamda_plus for up')

fig.add_subplot(3,2,6)
plt.imshow(lamda_u[1],cmap='gray')
plt.axis('off')
plt.title('lamda_minus for up')

#plt.savefig('lamda',format='png', bbox_inches='tight')

"""### 2.1.3

Κριτήριο Γωνιότητας
"""

#Importing helping function from lab
def disk_strel(n):
    '''
        Return a structural element, which is a disk of radius n.
    '''
    r = int(np.round(n))
    d = 2*r+1
    x = np.arange(d) - r
    y = np.arange(d) - r
    x, y = np.meshgrid(x,y)
    strel = x**2 + y**2 <= r**2
    return strel.astype(np.uint8)

def interest_points_visualization(I_, kp_data_, ax=None):
    '''
    Plot keypoints chosen by detectos on image.
    Args:
        I_: Image (if colored, make sure it is in RGB and not BGR).
        kp_data_: Nx3 array, as described in assignment.
        ax: Matplotlib axis to plot on (if None, a new Axes object is created).
    Returns:
        ax: Matplotlib axis where the image was plotted.
    '''
    try:
        I = np.array(I_)
        kp_data = np.array(kp_data_)
    except:
        print('Conversion to numpy arrays failed, check if the inputs (image and keypoints) are in the required format.')
        exit(2)

    try:
        assert(len(I.shape) == 2 or (len(I.shape) == 3 and I.shape[2] == 3))
    except AssertionError as e:
        print('interest_points_visualization: Image must be either a 2D matrix or a 3D matrix with the last dimension having size equal to 3.', file=sys.stderr)
        exit(2)

    try:
        assert(len(kp_data.shape) == 2 and kp_data.shape[1] == 3)
    except AssertionError as e:
        print('interest_points_visualization: kp_data must be a 2D matrix with 3 columns.', file=sys.stderr)
        exit(2)

    if ax is None:
        _, ax = plt.subplots()

    ax.set_aspect('equal')
    ax.imshow(I_)
    ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)

    for i in range(len(kp_data_)):
        y, x, sigma = kp_data_[i]
        circ = Circle((x, y), 3*sigma, edgecolor='y', fill=False, linewidth=1)
        ax.add_patch(circ)

    return ax

def find_coords(S, R, criterion):
  """This function takes as arguments the initial corner criterion of an image and 
  outputs the coordinates of the points that satisfy both Σ1 and Σ2"""

  arr=[]
  for x in range(S.shape[0]):
    for y in range(S.shape[1]):
      if (R[x][y] == S[x][y]) and (R[x][y] > criterion):
        arr.append((x,y))
  arr = np.array(arr)

  return arr

def fill_array(coordinates,sigma):
  """This function returns an array filled with the coordinates and the scale needed
  for the visulization function"""

  array=np.zeros((coordinates.shape[0],3))
  for x in range(coordinates.shape[0]):
    array[x] = (coordinates[x][0], coordinates[x][1], sigma) 

  return array


def corner_coordinates(image, s, r, k, theta_corn):
  """This function, returns an array which contains the coordinates of the corner points
  of the input image on scale s,r along with the scale on which they were detected"""


  #Creating eigenvalues for the input image
  J1, J2, J3 = tensor_J(image, s, r)
  lamda = lamda_values(J1,J2,J3)

  #Creating corner criterion

  R= (np.subtract((np.multiply(lamda[1],lamda[0])),(k*np.power(np.add(lamda[1],lamda[0]),2))))

  ns = int(np.ceil(3*s)*2+1)
  B_sq = disk_strel(ns)

  #Condition 1
  cond = cv2.dilate(R, B_sq)

  criterion= theta_corn*R.max()

  #Coordinates of point that satisft both criterion
  coords = find_coords(cond,R,criterion)

  #Array for visualization
  arr= fill_array(coords, s) 

  return arr

#Visualization of corners
arr = []
arr.append(corner_coordinates(kyot_img_gray, sigma, r, k, theta_corn))
arr.append(corner_coordinates(cells_img_gray, sigma, r, k, theta_corn))
arr.append(corner_coordinates(up_img_gray, sigma, r, k, theta_corn))

interest_points_visualization(kyot_img, arr[0], ax=None)
interest_points_visualization(cells_img, arr[1], ax=None)
interest_points_visualization(up_img, arr[2], ax=None)

"""## **2.2. Πολυκλιμακωτή Ανίχνευση Γωνιών**

### 2.2.1

Εύρεση γωνιών για διάφορες κλίμακες
"""

def produce_scales(sigma_zero, r_zero, s, N):
  #Produces σ and r for multiple scales
  sigma_scales = []
  r_scales = []
  for i in range(N):
    sigma_scales.append(math.pow(s, i)*sigma_zero)
    r_scales.append(math.pow(s, i)*r_zero)
  
  return sigma_scales, r_scales

#Detecting corners of cells image for 4 scales and initial conditions sigma=2, r=2.5
sigma_scale, r_scale = produce_scales(sigma, r, s, N)
scale_corner_coordinates_cells = []
scale_corner_coordinates_up = []
for i in range(len(sigma_scale)):
  scale_corner_coordinates_cells.append(corner_coordinates(cells_img_gray, sigma_scale[i], r_scale[i], k, theta_corn))
  scale_corner_coordinates_up.append(corner_coordinates(up_img_gray, sigma_scale[i], r_scale[i], k, theta_corn))

for i in range(len(sigma_scale)):
  interest_points_visualization(cells_img, scale_corner_coordinates_cells[i], ax=None)
  interest_points_visualization(up_img, scale_corner_coordinates_up[i], ax=None)

"""Παραπάνω τυπώσαμε τα σημεία που ανιχνεύει ο αλγόριθμος μας ως γωνίες σε 4 διαφορετικές κλίμακες για την εικόνα cells_image(Για εξοικονόμιση χώρου τυπώσαμε μόνο για αυτή την εικόνα ωστόσο παρόμοια αποτελέσματα παρατηρούμε και για την εικόνα up). Αυτό που διαπιστώνουμε είναι πως όσο η κλίμακα γίνεται πιο μεγάλη, παραμένουν κάποιες βασικές γωνίες και οι υπόλοιπες πολύ λεπτομερείς γωνίες δεν ανιχνεύονται.

### 2.2.2

Αρχικά βρίσκουμε τις κανονικοποιημένες LoG για κάθε μια απο τις προηγούμενες κλίμακες.
"""

norm_laplace_cells = []
norm_laplace_up = []
for s in (sigma_scale):
  norm_laplace_cells.append(laplaceImage('linear', s, cells_img_gray)*np.power(s,2))
  norm_laplace_up.append(laplaceImage('linear', s, up_img_gray)*np.power(s,2))

#What those different scale log images look like
fig = plt.figure(dpi=300)

fig.add_subplot(2,4,1)
plt.imshow(norm_laplace_cells[0], cmap='gray')
plt.axis('off')
plt.title("σ=2")

fig.add_subplot(2,4,2)
plt.imshow(norm_laplace_cells[1], cmap='gray')
plt.axis('off')
plt.title("σ=3")

fig.add_subplot(2,4,3)
plt.imshow(norm_laplace_cells[2], cmap='gray')
plt.axis('off')
plt.title("σ=4.5")

fig.add_subplot(2,4,4)
plt.imshow(norm_laplace_cells[3], cmap='gray')
plt.axis('off')
plt.title("σ=6.75")

fig.add_subplot(2,4,5)
plt.imshow(norm_laplace_up[0], cmap='gray')
plt.axis('off')
plt.title("σ=2")

fig.add_subplot(2,4,6)
plt.imshow(norm_laplace_up[1], cmap='gray')
plt.axis('off')
plt.title("σ=3")

fig.add_subplot(2,4,7)
plt.imshow(norm_laplace_up[2], cmap='gray')
plt.axis('off')
plt.title("σ=4.5")

fig.add_subplot(2,4,8)
plt.imshow(norm_laplace_up[3], cmap='gray')
plt.axis('off')
plt.title("σ=6.75")

def reject_corners(img, scale_coords, log):
  true_corners=[]
  for i in range(len(scale_coords)):
    for j in range(scale_coords[i].shape[0]):
      x = int(scale_coords[i][j][0])
      y = int(scale_coords[i][j][1])
      if i == 0:
        if log[i][x][y] > log[i+1][x][y]:
          true_corners.append((x, y, scale_coords[i][j][2]))

      elif i > 0 and i < (len(scale_coords)-1):
        if log[i][x][y] > log[i-1][x][y] and log[i][x][y] > log[i+1][x][y]:
          true_corners.append((x, y, scale_coords[i][j][2]))

      elif i == (len(scale_coords)-1):
        if log[i][x][y] > log[i-1][x][y]:
          true_corners.append((x, y, scale_coords[i][j][2]))

  return true_corners

cells_true_corners = reject_corners(cells_img_gray, scale_corner_coordinates_cells, norm_laplace_cells)
up_true_corners = reject_corners(up_img_gray, scale_corner_coordinates_up, norm_laplace_up)

interest_points_visualization(cells_img, cells_true_corners, ax=None)
interest_points_visualization(up_img, up_true_corners, ax=None)

"""## 2.3. Ανίχνευση Blobs

### 2.3.1
Υπολογισμός δεύτερων παραγώγων της εξομαλυμένης εικόνας Ισ
"""

def Hessian(image, sigma):
  """This function returns the det of Hessian matrix of input image"""


  #First we smooth the image
  ksize_s = int(np.ceil(3*sigma)*2 + 1)
  g_kernel_s = cv2.getGaussianKernel(ksize_s, sigma)

  smooth_img = cv2.filter2D(image,-1,g_kernel_s)

  gradient1 = np.gradient(smooth_img)
  gradient2 = np.gradient(gradient1[0])
  gradient3 = np.gradient(gradient1[1])

  partial_xx = gradient2[0]
  partial_xy = gradient2[1]
  partial_yy = gradient3[1]

  hessian = np.subtract(np.multiply(partial_xx,partial_yy), np.power(partial_xy,2))
  
  return hessian

"""### 2.3.2

Υπολογισμός σημείων blobs
"""

def find_blobs(image, s, r, k, theta_corn):
  """Returns the points of the blobs"""
  
  #Finds blobs

  R = Hessian(image, s)

  ns = int(np.ceil(3*s)*2+1)
  B_sq = disk_strel(ns)

  #Condition 1
  cond = cv2.dilate(R, B_sq)

  criterion= theta_corn*R.max()

  #Coordinates of point that satisft both criterion
  coords = find_coords(cond,R,criterion)

  #Array for visualization
  arr= fill_array(coords, s) 

  return arr

blob_coordinates = []
blob_coordinates.append(find_blobs(cells_img_gray, sigma, r, k, theta_corn))
blob_coordinates.append(find_blobs(up_img_gray, sigma, r, k, theta_corn))

interest_points_visualization(cells_img, blob_coordinates[0], ax=None)
interest_points_visualization(up_img, blob_coordinates[1], ax=None)

"""## 2.4. Πολυκλιμακωτή Ανίχνευση Blobs

### 2.4.1

Eφαρμόζουμε την ίδια διαδικασία κλιμακωτής ανίχνευσης γωνιών για τα blobs. Αρχικά, βρίσκουμε τις συντεταγμένες των blobs για τις διαφορετικές κλίμακες και στη συνέχεια απορρίπτουμε τα blobs σύμφωνα με τη συνθήκη κανονικοποιημένης LoG που εφαρμόστηκε και προηγουμένως.
"""

#Detecting blobs of images for 4 scales and initial conditions sigma=2, r=2.5
scale_blobs_coordinates_cells = []
scale_blobs_coordinates_up = []

for i in range(len(sigma_scale)):
  scale_blobs_coordinates_cells.append(find_blobs(cells_img_gray, sigma_scale[i], r_scale[i], k, theta_corn))
  scale_blobs_coordinates_up.append(find_blobs(up_img_gray, sigma_scale[i], r_scale[i], k, theta_corn))
for i in range(len(sigma_scale)):
  interest_points_visualization(cells_img, scale_blobs_coordinates_cells[i], ax=None)
  interest_points_visualization(up_img, scale_blobs_coordinates_up[i], ax=None)

"""Αυτά είναι τα blobs που ανιχνεύθηκαν για κάθε διαφορετική κλίμακα.

Στη συνέχεια, θα απορρίψουμε τα blobs που δεν παρουσιάζουν μέγιστο, όπως και με την ανίχνευση γωνών.
"""

def reject_blobs(img, blob_coords, log):
  true_blobs=[]
  for i in range(len(blob_coords)):
    for j in range(blob_coords[i].shape[0]):
      x = int(blob_coords[i][j][0])
      y = int(blob_coords[i][j][1])
      if i == 0:
        if log[i][x][y] > log[i+1][x][y]:
          true_blobs.append((x, y, blob_coords[i][j][2]))

      if i > 0 and i < (len(blob_coords)-1):
        if log[i][x][y] > log[i-1][x][y] and log[i][x][y] > log[i+1][x][y]:
          true_blobs.append((x, y, blob_coords[i][j][2]))

      if i == (len(blob_coords)-1):
        if log[i][x][y] > log[i-1][x][y]:
          true_blobs.append((x, y, blob_coords[i][j][2]))

  return true_blobs

cells_true_blobs = reject_blobs(cells_img_gray, scale_blobs_coordinates_cells, norm_laplace_cells)
up_true_blobs = reject_blobs(up_img_gray, scale_blobs_coordinates_up, norm_laplace_up)

interest_points_visualization(cells_img, cells_true_blobs, ax=None)
interest_points_visualization(up_img, up_true_blobs, ax=None)

"""## 2.5. Επιτάχυνση με την χρήση Box Filters και Ολοκληρωτικών Εικόνων (Integral Images)

### 2.5.1

Υπολογισμός ολοκληρωτικής εικόνας
"""

def integral(img):
    
    row = img.shape[0]
    col = img.shape[1]
    #integral image
    integral = np.zeros((img.shape[0],img.shape[1]))

    for i in range(0,row):
        for j in range(0,col):
            if i == 0 and j==0:
                integral[i][j] = img[i][j]
            elif i == 0:
                integral[i][j] = integral[i][j-1] + img[i][j]
            elif j==0:
                integral[i][j] = integral[i-1][j] + img[i][j]
            else:
                integral[i][j] = integral[i-1][j] + integral[i][j-1] - integral[i-1][j-1] + img[i][j]


    return integral

cells_integral = integral(cells_img_gray)
up_integral = integral(up_img_gray)

fig = plt.figure(dpi=150)

fig.add_subplot(1,2,1)
plt.imshow(cells_integral)
plt.axis('off')
plt.title('integral image of cells image')

fig.add_subplot(1,2,2)
plt.imshow(up_integral)
plt.axis('off')
plt.title('integral image of up image')

"""### 2.5.2

Υλοποίηση box filters
"""

def sum_points(i, j, integral, filter_type,s, padding_up, padding_left):
  """Returns the sum of a subarea of an image using the integral of the
  image through the points of coordinates:
  """
  n = int(2*np.ceil(3*s)+1)
  i = i + padding_up 
  j = j + padding_left

  if filter_type == 'Dxx':
    height = 4*np.floor(n/6)+1
    width = 2*np.floor(n/6)+1

    '''
           up
    left  (i,j)  right
          down
    '''
    down = int(i + np.floor(height/2))
    up = int(i - np.ceil(height/2))
    left = int(j - np.ceil(width/2))
    right = int(j + np.floor(width/2))

    x1, y1 = (down, right)
    x2, y2 = (up, right)
    x3, y3 = (up, left)
    x4, y4 = (down, left)
    x5, y5 = (up, int(left - width))
    x6, y6 = (down, int(left - width))
    x7, y7 = (down, int(right + width))
    x8, y8 = (up, int(right + width))

    first_window_sum = (integral[x4][y4] - integral[x3][y3] - integral[x6][y6] + integral[x5][y5])
    second_window_sum = (integral[x1][y1] - integral[x2][y2] - integral[x4][y4] + integral[x3][y3])
    third_window_sum = (integral[x7][y7] - integral[x8][y8] - integral[x1][y1] + integral[x2][y2])
    
    sum = first_window_sum + (-2)*second_window_sum + third_window_sum

  elif filter_type == 'Dyy':
    height = 2*np.floor(n/6)+1
    width = 4*np.floor(n/6)+1

    down = int(i + np.floor(height/2))
    up = int(i - np.ceil(height/2))
    left = int(j - np.ceil(width/2))
    right = int(j + np.floor(width/2))   

    x1, y1 = (down, right)
    x2, y2 = (up, right)
    x3, y3 = (up, left)
    x4, y4 = (down, left)
    x5, y5 = (int(up - height), right)
    x6, y6 = (int(up - height), left)
    x7, y7 = (int(down + height), right)
    x8, y8 = (int(down + height), left)

    first_window_sum = (integral[x2][y2] - integral[x5][y5] - integral[x3][y3] + integral[x6][y6])
    second_window_sum = (integral[x1][y1] - integral[x2][y2] - integral[x4][y4] + integral[x3][y3])
    third_window_sum = (integral[x7][y7] - integral[x8][y8] - integral[x1][y1] + integral[x4][y4])
    
    sum = first_window_sum + (-2)*second_window_sum + third_window_sum

  elif filter_type == 'Dxy':
    height = 2*np.floor(n/6)+1
    width = 2*np.floor(n/6)+1 

    x1, y1 = (int(i - 1), int(j - 1))
    x2, y2 = (int(i - (height + 1)), int(j-1))
    x3, y3 = (int(i - (height + 1) ), int(j - (width + 1)))
    x4, y4 = (int(i - 1), int(j - (width + 1)))
    x5, y5 = (int(i - 1), int(j + width))
    x6, y6 = (int(i - (height + 1)), int(j + width))
    x7, y7 = (int(i - (height + 1)), int(j))
    x8, y8 = (int(i - 1), int(j))
    x9, y9 = (int(i + height), int(j + width))
    x10, y10 = (int(i), int(j + width))
    x11, y11 = (int(i), int(j))
    x12, y12 = (int(i + height), int(j))
    x13, y13 = (int(i + height), int(j - 1))
    x14, y14 = (int(i), int(j - 1))
    x15, y15 = (int(i), int(j - (width + 1)))
    x16, y16 = (int(i + height), int(j - (width + 1)))

    first_window_sum = (integral[x1][y1] - integral[x2][y2] - integral[x4][y4] + integral[x3][y3])
    second_window_sum = (integral[x5][y5] - integral[x6][y6] - integral[x8][y8] + integral[x7][y7])
    third_window_sum = (integral[x13][y13] - integral[x14][y14] - integral[x16][y16] + integral[x15][y15])
    fourth_window_sum = (integral[x9][y9] - integral[x10][y10] - integral[x12][y12] + integral[x11][y11])

    sum = first_window_sum + (-1)*second_window_sum + (-1)*third_window_sum + fourth_window_sum


  return sum

  


def convolve_with_box(image, image_integral ,filter_type, s):
  """Depending on the filter type={Dxx,Dyy,Dxy} it outputs the 
  Lxx, Lyy and Lxy of the input image, using a box filter and the values of 
  its integral image"""

  n = int(2*np.ceil(3*s) + 1)
  X, Y = image.shape

  L = np.zeros((X , Y))
  

  if filter_type =='Dxx':

    #padding image with zeros for the output to have same size
    padding_up = int(2*np.floor(n/6)+1)
    padding_left = int(4*np.floor(n/6)+1)
    padding_down = int(2*np.floor(n/6)+1)
    padding_right = int(4*np.floor(n/6)+1)

    padded_img = np.pad(image_integral, ((padding_up, padding_down), (padding_left, padding_right)), 'reflect')
  
    for i in range(X):
      for j in range(Y):

          L[i][j] = sum_points(i, j, padded_img,'Dxx',s,padding_up, padding_left)

  elif filter_type =='Dyy':

    #padding image with zeros for the output to have same size
    padding_up = int(4*np.floor(n/6)+1)
    padding_left = int(2*np.floor(n/6)+1)
    padding_down = int(4*np.floor(n/6)+1)
    padding_right = int(2*np.floor(n/6)+1)

    padded_img = np.pad(image_integral, ((padding_up, padding_down), (padding_left, padding_right)), 'reflect')

    for i in range(X):
      for j in range(Y):

        L[i][j] = sum_points(i, j, padded_img,'Dyy',s, padding_up, padding_left)

  elif filter_type =='Dxy':

    #padding image with zeros for the output to have same size
    padding_up = int(2*np.floor(n/6)+2)
    padding_left = int(2*np.floor(n/6)+2)
    padding_down = int(2*np.floor(n/6)+2)
    padding_right = int(2*np.floor(n/6)+2)

    padded_img = np.pad(image_integral, ((padding_up, padding_down), (padding_left, padding_right)), 'reflect')

    for i in range(X):
      for j in range(Y):
      
        L[i][j] = sum_points(i, j, padded_img,'Dxy',s, padding_up, padding_left)

  return L

sigma_test = 1.2
Lxx = convolve_with_box(cells_img_gray, cells_integral, 'Dxx', sigma_test)
Lyy = convolve_with_box(cells_img_gray, cells_integral, 'Dyy', sigma_test)
Lxy = convolve_with_box(cells_img_gray, cells_integral, 'Dxy', sigma_test)

fig = plt.figure(dpi=200)

fig.add_subplot(1,3,1)

plt.imshow(Lxx, cmap='gray')
plt.axis('off')
plt.title('Lxx')


fig.add_subplot(1,3,2)
plt.imshow(Lyy, cmap='gray')
plt.axis('off')
plt.title('Lyy')

fig.add_subplot(1,3,3)
plt.imshow(Lxy,cmap='gray')
plt.axis('off')
plt.title('Lxy')

#Comparing with the actual Lxx, Lyy, Lxy
ksize_s = int(np.ceil(3*sigma_test)*2 + 1)
g_kernel_s = cv2.getGaussianKernel(ksize_s, sigma_test)

smooth_img = cv2.filter2D(cells_img_gray,-1,g_kernel_s)

gradient1 = np.gradient(smooth_img)
gradient2 = np.gradient(gradient1[0])
gradient3 = np.gradient(gradient1[1])

partial_xx = gradient2[0]
partial_xy = gradient2[1]
partial_yy = gradient3[1]

fig = plt.figure(dpi=200)

fig.add_subplot(1,3,1)
plt.imshow(partial_xx,cmap='gray')
plt.axis('off')
plt.title('partial_xx')

fig.add_subplot(1,3,2)
plt.imshow(partial_yy, cmap='gray')
plt.axis('off')
plt.title('partial_yy')

fig.add_subplot(1,3,3)
plt.imshow(partial_xy,cmap='gray')
plt.axis('off')
plt.title('partial_xy')

"""Παραπάνω εμφανίσαμε τα Lxx, Lyy, Lxy όπως υπολογίζονται με box_filters και με gradients αντίστοιχα.

### 2.5.3

Υπολογισμός κριτηρίου R της Hessian μεθόδου.
"""

Rbox = np.subtract(np.multiply(Lxx,Lyy),0.9*np.power(Lxy,2))
Rsimple = Hessian(cells_img_gray, sigma_test)

fig = plt.figure(dpi=200)

fig.add_subplot(1,2,1)
plt.imshow(Rbox, cmap='gray')
plt.axis('off')
plt.title('R with box filter')

fig.add_subplot(1,2,2)
plt.imshow(Rsimple, cmap='gray')
plt.axis('off')
plt.title('R of simple Hessian Method')

scales = [2.2, 3.1, 5.1, 7.2]

Lxx_approx = []
Lyy_approx = []
Lxy_approx = []

for sc in scales:

  Lxx_approx.append(convolve_with_box(cells_img_gray, cells_integral, 'Dxx', sc))
  Lyy_approx.append(convolve_with_box(cells_img_gray, cells_integral, 'Dyy', sc))
  Lxy_approx.append(convolve_with_box(cells_img_gray, cells_integral, 'Dxy', sc))

Rbox_approx = []
for i in range(len(scales)):

  Rbox_approx.append(np.subtract(np.multiply(Lxx_approx[i],Lyy_approx[i]),0.9*np.power(Lxy_approx[i],2)))

R_simple_approx = []
for s in scales:
  R_simple_approx.append(Hessian(cells_img_gray, s))

fig = plt.figure(dpi=300)

fig.add_subplot(4,2,1)
plt.imshow(Rbox_approx[0],cmap='gray')
plt.axis('off')
plt.title('σ=2.3')

fig.add_subplot(4,2,2)
plt.imshow(R_simple_approx[0],cmap='gray')
plt.axis('off')
plt.title('σ=2.3')

fig.add_subplot(4,2,3)
plt.imshow(Rbox_approx[1],cmap='gray')
plt.axis('off')
plt.title('σ=4.4')

fig.add_subplot(4,2,4)
plt.imshow(R_simple_approx[1],cmap='gray')
plt.axis('off')
plt.title('σ=4.4')

fig.add_subplot(4,2,5)
plt.imshow(Rbox_approx[2],cmap='gray')
plt.axis('off')
plt.title('σ=6.5')

fig.add_subplot(4,2,6)
plt.imshow(R_simple_approx[2],cmap='gray')
plt.axis('off')
plt.title('σ=6.5')

fig.add_subplot(4,2,7)
plt.imshow(Rbox_approx[3],cmap='gray')
plt.axis('off')
plt.title('σ=8.7')

fig.add_subplot(4,2,8)
plt.imshow(R_simple_approx[3],cmap='gray')
plt.axis('off')
plt.title('σ=8.7')

"""### 2.5.4

Υπολογίζουμε τα σημεία ενδιαφέροντος χρησιμοποιώντας τη μέθοδο των box filters χρησιμοποιώντας τις ίδιες ενδεικτικές τιμές παραμέτρων που χρησιμοποιήσαμε και προηγουμένως.
"""

def find_blobs_box(image, s, r, k, theta_corn):
  """Returns the points of the blobs"""
  
  # Integral image
  Integral = integral(image)

  #Finds blobs
  Lxx = convolve_with_box(image, Integral, 'Dxx', s)
  Lyy = convolve_with_box(image, Integral, 'Dyy', s)
  Lxy = convolve_with_box(image, Integral, 'Dxy', s)

  Rbox = np.subtract(np.multiply(Lxx,Lyy),0.9*np.power(Lxy,2))

  ns = int(np.ceil(3*s)*2+1)
  B_sq = disk_strel(ns)

  #Condition 1
  cond = cv2.dilate(Rbox, B_sq)

  criterion= theta_corn*Rbox.max()

  #Coordinates of point that satisft both criterion
  coords = find_coords(cond,Rbox,criterion)

  #Array for visualization
  arr= fill_array(coords, s) 

  return arr

#Recommended vaules:
sigma = 2
r = 2.5
k = 0.1
theta_corn = 0.05
s = 1.5
N = 4

blob_coordinates_box = []
blob_coordinates_box.append(find_blobs_box(cells_img_gray, sigma, r, k, theta_corn))
blob_coordinates_box.append(find_blobs_box(up_img_gray, sigma, r, k, theta_corn))

interest_points_visualization(cells_img, blob_coordinates_box[0], ax=None)
interest_points_visualization(up_img, blob_coordinates_box[1], ax=None)

"""Παρατηρούμε πως ανιχνεύονται σχεδόν ίδια σημεία blobs.

***Πολυκλιμακωτή ανίχνευση blobs με χρήση box filters***
"""

sigma_scale, r_scale = produce_scales(sigma, r, s, N)


def multiscale_blobs_box(img):

  Integral = integral(img)

  blob_coords = []

  for i in range(len(sigma_scale)):
    blob_coords.append(find_blobs_box(img, sigma_scale[i], r_scale[i], k, theta_corn))
    
  log = []
  for s in (sigma_scale):
    Lxx = convolve_with_box(img, Integral, 'Dxx', s)
    Lyy = convolve_with_box(img, Integral, 'Dyy', s)
    Lxy = convolve_with_box(img, Integral, 'Dxy', s)

    log.append(np.power(s,2) * (Lxx + Lyy))

  true_blobs=[]
  for i in range(len(blob_coords)):
    for j in range(blob_coords[i].shape[0]):
      x = int(blob_coords[i][j][0])
      y = int(blob_coords[i][j][1])
      if i == 0:
        if log[i][x][y] > log[i+1][x][y]:
          true_blobs.append((x, y, blob_coords[i][j][2]))

      if i > 0 and i < (len(blob_coords)-1):
        if log[i][x][y] > log[i-1][x][y] and log[i][x][y] > log[i+1][x][y]:
          true_blobs.append((x, y, blob_coords[i][j][2]))

      if i == (len(blob_coords)-1):
        if log[i][x][y] > log[i-1][x][y]:
          true_blobs.append((x, y, blob_coords[i][j][2]))

  return true_blobs



cells_true_blobs_box = multiscale_blobs_box(cells_img_gray)
up_true_blobs_box = multiscale_blobs_box(up_img_gray)

interest_points_visualization(cells_img, cells_true_blobs_box, ax=None)
interest_points_visualization(up_img, up_true_blobs_box, ax=None)

"""Παρατηρούμε πως βρέθηκαν σχετικά παρόμοια scale-invariant σημεία με αυτή τη μέθοδο, ωστόσο πέρνει πολύ περισσότερη ώρα απότι περιμέναμε."""
